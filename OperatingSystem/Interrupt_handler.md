In computer systems programming, an __interrupt handler__, also known as an __interrupt service routine__ or __ISR__, is a special block of code associated with a specific interrupt condition. Interrupt handlers are initiated by hardware interrupts, software interrupt instructions, or software exceptions, and are used for implementing device drivers or transitions between protected modes of operation, such as system calls.

The traditional form of interrupt handler is the hardware interrupt handler. Hardware interrupts arise from electrical conditions or low-level protocols implemented in digital logic, are usually dispatched via a hard-coded table of interrupt vectors, asynchronously to the normal execution stream (as interrupt masking levels permit), often using a separate stack, and automatically entering into a different execution context (privilege level) for the duration of the interrupt handler's execution. In general, hardware interrupts and their handlers are used to handle high-priority conditions that require the interruption of the current code the processor is executing.

Later it was found convenient for software to be able to trigger the same mechanism by means of a software interrupt (a form of synchronous interrupt). Rather than using a hard-coded interrupt dispatch table at the hardware level, software interrupts are often implemented at the operating system level as a form of callback function.

Interrupt handlers have a multitude of functions, which vary based on what triggered the interrupt and the speed at which the interrupt handler completes its task. For example, pressing a key on a computer keyboard, or moving the mouse, triggers interrupts that call interrupt handlers which read the key, or the mouse's position, and copy the associated information into the computer's memory.

An interrupt handler is a low-level counterpart of event handlers. However, interrupt handlers have an unusual execution context, many harsh constraints in time and space, and their intrinsically asynchronous nature makes them notoriously difficult to debug by standard practice (reproducible test cases generally don't exist), thus demanding a specialized skillset—an important subset of system programming—of software engineers who engage at the hardware interrupt layer.

#### What is the difference between context switching and interrupt handling?

That is an insightful question - there are similarities and differences. It is important to understand what each is and why they exist.

Context switching is the process of switching a process from working on one task to working on another even before the former task is completed. This involves saving the state of all volatile data like registers, program counter, memory, etc. (in other words the "context")  to persistent storage and then loading up the context of a new process. Or just starting up a new process from scratch which will have its own context. This technique allows a process to concurrently work on multiple tasks without the necessity of requiring one to run to completion. 

Interrupt handling is the process of a processor or process receiving an asynchronous signal that typically requires it to "drop" what ever it is doing and work on this interrupt immediately.  By definition it requires a context switch to accomplish this. Once the interrupt is serviced the earlier task can resume. Interrupts can be hardware (which seem to be what you are referring to) or software (like UNIX signals). 

So Interrupt handling does require a context switch and your real question probably was - are the terms interchangeable?  No, because you can have a t context switch that is not driven by an asynchronous unpredictable interrupt.  The most obvious use would be in a multi-tasked operating system that allows for multiple processes to run concurrently on the same processor (not to be confused with parallel processing on different processors). To do this the OS needs the ability to execute part of a process, save its state and then execute another process. In a time shared operating system this would be done by giving a fixed time slice shared in a round robin between processes. There are other ways too, based on condition synchronization etc.

So in a nutshell, interrupt handling is just one example of why you would need context switching. As a few minor comments on your question, it is unlikely processor state would be saved in a stack, it would probably be on a heap. Because the pattern does not have to be LIFO. Also a controller very much has an operating system. It just isn't a big famous operating system like Windows or Linux. By definition it has an operating system because that is what is doing the context switching.  It just is a relatively simple embedded operating system.
